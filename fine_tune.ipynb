{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "fine_tune.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N6ZDpd9XzFeN"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "KUu4vOt5zI9d",
        "colab": {}
      },
      "source": [
        "# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "edfbxDDh2AEs"
      },
      "source": [
        "## Predict vtuber danmaku with Cloud TPUs and Keras\n",
        "#### Modified from \"Predict Shakespeare with Cloud TPUs and Keras\"\n",
        "Author github ID: pren1, coco401, simon3000, Afanyiyu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RNo1Vfghpa8j"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This example uses [tf.keras](https://www.tensorflow.org/guide/keras) to build a *language model* and train it on a Cloud TPU. This language model predicts the next character of text given the text so far. The trained model can generate new snippets of text that read in a similar style to the text training data.\n",
        "\n",
        "The model trains for 10 epochs and completes in approximately 1 hour."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QrprJD-R-410"
      },
      "source": [
        "## Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_I0RdnOSkNmi"
      },
      "source": [
        "<h3>  &nbsp;&nbsp;Train on TPU&nbsp;&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a></h3>\n",
        "\n",
        "   1. On the main menu, click Runtime and select **Change runtime type**. Set \"TPU\" as the hardware accelerator.\n",
        "   1. Click Runtime again and select **Runtime > Run All**. You can also run the cells manually with Shift-ENTER. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kYxeFuKCUx9d"
      },
      "source": [
        "TPUs are located in Google Cloud, for optimal performance, they read data directly from Google Cloud Storage (GCS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lvo0t7XVIkWZ"
      },
      "source": [
        "## Data, model, and training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xzpUtDMqmA-x"
      },
      "source": [
        "In this file, you train the model utilizing the danmaku data shown below:\n",
        "\n",
        "<blockquote>\n",
        "[\"完事\",\"了\",\"这\",\"是\",\"？\"],\n",
        "\n",
        "[\"来\",\"了\"],\n",
        "\n",
        "[\"哇\",\"我\",\"刚\",\"忙\",\"完\",\"o\",\"r\",\"z\"]\n",
        "</blockquote>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USsmqZM9n4T_",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KRQ6Fjra3Ruq"
      },
      "source": [
        "### Download data\n",
        "You use snippets from this file as the *training data* for the model. The *target* snippet is offset by one character."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEpdTZVIYXaR",
        "colab_type": "code",
        "outputId": "3c391dfd-0ff0-4322-c20d-693ce35f816e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "# !gdown https://drive.google.com/uc?id=1QWBjb9vk8TZhc9tZqxV1-BbVTj0GlMBy\n",
        "# !gdown https://drive.google.com/uc?id=1i6JH7x7SsAFYYX_EU1z5DHr1YQKeVyzN\n",
        "\n",
        "# !gdown https://drive.google.com/uc?id=1bRf5YnXh8dkLwqgz4IdqaxRMKmzq0pxI\n",
        "# !gdown https://drive.google.com/uc?id=1jEo1ObjoHqI0JuPsCQuRndxw6xIPxjoR\n",
        "# !gdown https://drive.google.com/uc?id=1tBO5Bxfu3FRLLuudIQ_xHvi0t6LfO34m\n",
        "\n",
        "# !gdown https://drive.google.com/uc?id=1DEVIMMeCLqtsiOKA3TgX2KRSDdvjhuYr\n",
        "# !gdown https://drive.google.com/uc?id=1T5OpFmiT00MFZYNHyGFXqpEcLvdIBVOr\n",
        "\n",
        "# !gdown https://drive.google.com/uc?id=169jYxkPev2lkfMy8eu497EuukLxXcMF-\n",
        "\n",
        "\n",
        "# !gdown https://drive.google.com/uc?id=1V5juWnxQXwOOxJarxJ0V8-nVPF87QshX\n",
        "# !gdown https://drive.google.com/uc?id=1B0UaIeixggEg30SUw3uvWxDGbabJo9NV\n",
        "# !gdown https://drive.google.com/uc?id=1QLl2kqsPDoWhbmM22N9bdt1gOsuLRAdv\n",
        "\n",
        "'128'\n",
        "# !gdown https://drive.google.com/uc?id=12taxnPvsqgaQuJDW9d1Pqzsz7ykR5rub\n",
        "# !gdown https://drive.google.com/uc?id=1HuJT-GXvgZUs8turPoKP2tEvZJEc_uNH\n",
        "# !gdown https://drive.google.com/uc?id=1GHG5S-LiEI-hCp47hxt6whZVbgqv3V8k\n",
        "\n",
        "# !gdown https://drive.google.com/uc?id=1CPRLIVGlCwG2OshG1Ix5PGFO6z2G8pzc\n",
        "\n",
        "# !gdown https://drive.google.com/uc?id=11oycRZUgPN3eFgQy_ZvADUwv9IzUEt0g\n",
        "# !gdown https://drive.google.com/uc?id=1wRVWnrJJPXz4E6I8x2sIoxlOFdWu1uMJ\n",
        "\n",
        "\n",
        "'512'\n",
        "# !gdown https://drive.google.com/uc?id=1yzco4NHi7pCb9RLCT_rPWzv-SxjRvvrN\n",
        "# !gdown https://drive.google.com/uc?id=11hhsqbAvSC-qxo1eoiV2jUqDK2Ta-fuB\n",
        "# !gdown https://drive.google.com/uc?id=1AOtc7nFGPr34YoS7uUkmSovVOfSenKMF\n",
        "\n",
        "'512 new'\n",
        "# !gdown https://drive.google.com/uc?id=1zEy1FI8IJJNPqbF_u4fw1LYb6LRJFcR8\n",
        "# !gdown https://drive.google.com/uc?id=11KWv0drUpoEcJto6lkrw3QJRxWFXsxdK\n",
        "# !gdown https://drive.google.com/uc?id=1BNho7u9E3bpRnIUrkJzyqFxHg1xgtFCW\n",
        "\n",
        "'512 large'\n",
        "!gdown https://drive.google.com/uc?id=1VNrzw-NOCVHp2J2dQIgs9Esd2hNi-UP9\n",
        "!gdown https://drive.google.com/uc?id=1UHAUWW-et7dm3yxPL-D6zjEc4g-MTU97\n",
        "!gdown https://drive.google.com/uc?id=1_R_FiqrlVdZlN2Fy8xHx2bwq9ZYyu31o\n",
        "\n",
        "# https://drive.google.com/file/d/1VNrzw-NOCVHp2J2dQIgs9Esd2hNi-UP9/view?usp=sharing\n",
        "# https://drive.google.com/file/d/1UHAUWW-et7dm3yxPL-D6zjEc4g-MTU97/view?usp=sharing\n",
        "# https://drive.google.com/file/d/1_R_FiqrlVdZlN2Fy8xHx2bwq9ZYyu31o/view?usp=sharing"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1VNrzw-NOCVHp2J2dQIgs9Esd2hNi-UP9\n",
            "To: /content/fin_fresh_512.json\n",
            "1.65GB [00:15, 109MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1UHAUWW-et7dm3yxPL-D6zjEc4g-MTU97\n",
            "To: /content/glove-512-words.pkl\n",
            "100% 166k/166k [00:00<00:00, 58.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_R_FiqrlVdZlN2Fy8xHx2bwq9ZYyu31o\n",
            "To: /content/glove-512.npy\n",
            "22.2MB [00:00, 104MB/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhXFaG8qtvfW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !gdown https://drive.google.com/uc?id=1FFSNsBeFlevU8v3xfQCUvDCBNSuP52PL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x15pAi9ShXdU",
        "colab_type": "text"
      },
      "source": [
        "## Process the data with index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmWOiUB4hV24",
        "colab_type": "code",
        "outputId": "73d57f47-8b13-4570-c146-f27b188aff2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import pdb\n",
        "import collections\n",
        "import distutils\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "from keras.utils import plot_model\n",
        "\n",
        "# 'the character should occur this much time if they wanna to be taken into account'\n",
        "# minimum_occur_time = 100\n",
        "context_vector_length = 100\n",
        "context_seq_length = 130\n",
        "batch_size = 2048\n",
        "# SHAKESPEARE_TXT = '/content/bert-master_danmaku_text_pure.txt'\n",
        "# 'Use the following path to just save you some time'\n",
        "# preprocessed_TXT = '/content/rectified_input.txt'\n",
        "# characters, rare_characters, input_text = process_data_with_index(SHAKESPEARE_TXT, minimum_occur_time)\n",
        "\n",
        "'load in characters, and embedding matrix'\n",
        "with open('/content/glove-512-words.pkl', 'rb') as f:\n",
        "    characters = pickle.load(f)\n",
        "    'also add end part, and beginning part'\n",
        "    '成雨'\n",
        "    characters[-1] = 'eos'\n",
        "    '効'\n",
        "    characters[-2] = '\\n'\n",
        "# preprocessed_TXT = '/content/new_filtered_data.json'\n",
        "preprocessed_TXT = '/content/fin_fresh_512.json'\n",
        "# preprocessed_TXT = '/content/fbk_fine_tune.json'\n",
        "embedding_matrix = np.load('/content/glove-512.npy')\n",
        "'show something about embedding'\n",
        "\n",
        "char_to_n = {char:n for n, char in enumerate(characters)}\n",
        "n_to_char = {n:char for n, char in enumerate(characters)}\n",
        "\n",
        "def transform(txt):\n",
        "    return np.asarray([char_to_n[c] for c in txt], dtype=np.int32)\n",
        "\n",
        "# def remove_unkown_character_from_text(txt, rare_characters):\n",
        "#     'Remove char in rare_characters from txt' \n",
        "#     for x in tqdm(rare_characters):\n",
        "#         try:\n",
        "#             txt = txt.replace(x, \"\")\n",
        "#         except ValueError:\n",
        "#             pass\n",
        "#     return txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E3V4V-Jxmuv3",
        "colab": {}
      },
      "source": [
        "# This address identifies the TPU we'll use when configuring TensorFlow.\n",
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "import json\n",
        "def input_fn(seq_len=context_seq_length, batch_size=batch_size):\n",
        "  \"\"\"Return a dataset of source and target sequences for training.\"\"\"\n",
        "  with open(preprocessed_TXT, encoding='UTF-8') as json_file:\n",
        "    data = json.load(json_file, encoding='UTF-8')\n",
        "    # data = data[:100000]\n",
        "    'process the data'\n",
        "    txt = []\n",
        "    label_part = []\n",
        "    for single_meg in tqdm(data):\n",
        "      single_meg[0].insert(0, 'eos')\n",
        "      single_meg[0].append('\\n')\n",
        "      label = [single_meg[1]] * len(single_meg[0])\n",
        "      txt.extend(single_meg[0])\n",
        "      label_part.extend(label)\n",
        "    # occur_index =[i for i in range(len(txt)) if txt[i] in ['口呆口', 'magnet']]\n",
        "    \n",
        "    new_txt = []\n",
        "    new_label_part = []\n",
        "    for (single, label) in tqdm(zip(txt, label_part)):\n",
        "      if single not in  ['成雨', '効']:\n",
        "        new_txt.append(single)\n",
        "        new_label_part.append(label)\n",
        "    txt = tf.constant(transform(new_txt), dtype=tf.int32)\n",
        "    label_part = tf.constant(new_label_part, dtype=tf.int32)\n",
        "    print(\"Processing the txt: {}, with label: {}\".format(txt[1000:1020], label_part[1000:1020]))\n",
        "    'If the input is preprocessed_TXT, then you do not need this one'\n",
        "    # txt = remove_unkown_character_from_text(txt, rare_characters)\n",
        "  # txt = np.asarray(txt)\n",
        "  # label_part = np.asarray(label_part)\n",
        "  # source = tf.constant(transform(res), dtype=tf.int32)\n",
        "  \n",
        "  # def generator():\n",
        "  #   for txt_sig, label_sig in zip(txt, label_part):\n",
        "  #     yield txt_sig, label_sig\n",
        "  \n",
        "  # ds = tf.data.Dataset.from_generator(generator, output_types=(tf.string, tf.int32)).batch(seq_len+1, drop_remainder=True)\n",
        "  import time\n",
        "  start_time = time.time()\n",
        "  ds = tf.data.Dataset.from_tensor_slices((txt, label_part)).batch(seq_len+1, drop_remainder=True)\n",
        "  print(\"--- slice tensor spends: %s seconds ---\" % (time.time() - start_time))\n",
        "  # ds = tf.data.Dataset.from_tensor_slices(source).batch(seq_len+1, drop_remainder=True)\n",
        "\n",
        "  def split_input_target(chunk, label_chunk):\n",
        "    context_vector = chunk[:context_vector_length]\n",
        "    input_text = chunk[context_vector_length:-1]\n",
        "    target_text = chunk[context_vector_length+1:]\n",
        "    'Simply use the first element as the chunk label'\n",
        "    label_value = label_chunk[:1]\n",
        "    return (context_vector, input_text, label_value), target_text\n",
        "\n",
        "  BUFFER_SIZE = 10000\n",
        "  ds = ds.map(split_input_target).shuffle(BUFFER_SIZE).batch(batch_size, drop_remainder=True)\n",
        "  return ds.repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Bbb05dNynDrQ"
      },
      "source": [
        "### Build the model\n",
        "\n",
        "The model is defined as a two-layer, forward-LSTM, the same model should work both on CPU and TPU.\n",
        "\n",
        "The input dimension to the Embedding layer is the same as our vocabulary size.\n",
        "\n",
        "When specifying the arguments to the LSTM, it is important to note how the stateful argument is used. When training we will make sure that `stateful=False` because we do want to reset the state of our model between batches, but when sampling (computing predictions) from a trained model, we want `stateful=True` so that the model can retain information across the current batch and generate more interesting text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yLEM-fLJlEEt",
        "colab": {}
      },
      "source": [
        "EMBEDDING_DIM = 512\n",
        "HALF_EMBEDDING_DIM = int(EMBEDDING_DIM/2)\n",
        "regularizer_coefficient = 0.000001\n",
        "dropout_rate = 0.4\n",
        "def lstm_model(seq_len=30, context_length = context_vector_length, batch_size=None, stateful=True):\n",
        "    \"\"\"Language model: Encoder decoder favor for context term\"\"\"\n",
        "    room_id_bit =  tf.keras.Input(name='room_id_bit', shape=(1,), batch_size=batch_size, dtype=tf.int32)\n",
        "    one_hot_embedding_id = tf.keras.backend.one_hot(room_id_bit, num_classes = EMBEDDING_DIM)\n",
        "\n",
        "    encoder_input = tf.keras.Input(name='Encoder_input', shape=(context_length,), batch_size=batch_size, dtype=tf.int32)\n",
        "    embedding_layer = tf.keras.layers.Embedding(input_dim=len(characters), output_dim=EMBEDDING_DIM, embeddings_initializer = tf.keras.initializers.Constant(embedding_matrix), trainable=False)\n",
        "    encode_embedding = embedding_layer(encoder_input)\n",
        "    'Then, we concatenate the embedding to provide more info'\n",
        "    rich_info_embedding = tf.keras.layers.concatenate([encode_embedding, one_hot_embedding_id],axis=1)\n",
        "\n",
        "    enc_lstm1, forward_h, forward_c, backward_h, backward_c = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(HALF_EMBEDDING_DIM, name='encoder_lstm_1', return_state=True, return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(regularizer_coefficient)))(rich_info_embedding)\n",
        "    state_h_1 = tf.keras.layers.concatenate([forward_h, backward_h])\n",
        "    state_c_1 = tf.keras.layers.concatenate([forward_c, backward_c])\n",
        "    enc_lstm1 = tf.keras.layers.Dropout(dropout_rate)(enc_lstm1)\n",
        "    encoder_states_1 = [state_h_1, state_c_1]\n",
        "\n",
        "    enc_lstm2, forward_h, forward_c, backward_h, backward_c = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(HALF_EMBEDDING_DIM, name='encoder_lstm_2', return_state=True, return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(regularizer_coefficient)))(enc_lstm1)\n",
        "    \n",
        "    'Double concatenate'\n",
        "    enc_lstm2 = tf.keras.layers.concatenate([enc_lstm2, one_hot_embedding_id],axis=1)\n",
        "\n",
        "    state_h_2 = tf.keras.layers.concatenate([forward_h, backward_h])\n",
        "    state_c_2 = tf.keras.layers.concatenate([forward_c, backward_c])\n",
        "    encoder_states_2 = [state_h_2, state_c_2]\n",
        "    # Set up the decoder, using `encoder_states` as initial state.\n",
        "    decoder_inputs = tf.keras.Input(name='Decoder_input', shape=(seq_len,), batch_size=batch_size, dtype=tf.int32)\n",
        "    decode_embedding = embedding_layer(decoder_inputs)\n",
        "    lstm_1_layer = tf.keras.layers.LSTM(EMBEDDING_DIM, name='decoder_lstm_1', stateful=stateful, return_state=True, return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(regularizer_coefficient))\n",
        "    lstm_1, _, _ = lstm_1_layer(decode_embedding, initial_state=encoder_states_1)\n",
        "    dropout_lstm_1 = tf.keras.layers.Dropout(dropout_rate)(lstm_1)\n",
        "    lstm_2_layer = tf.keras.layers.LSTM(EMBEDDING_DIM, name='decoder_lstm_2', stateful=stateful, return_state=True, return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(regularizer_coefficient))\n",
        "    lstm_2, _, _  = lstm_2_layer(dropout_lstm_1, initial_state=encoder_states_2)\n",
        "    dropout_lstm_2 = tf.keras.layers.Dropout(dropout_rate)(lstm_2)\n",
        "\n",
        "    'try to add attention here~'\n",
        "    attention = tf.keras.layers.Dot(axes=[2, 2])([dropout_lstm_2, enc_lstm2])\n",
        "    attention = tf.keras.layers.Activation('softmax', name='attention')(attention)\n",
        "    context = tf.keras.layers.Dot(axes=[2, 1])([attention, enc_lstm2])\n",
        "    decoder_combined_context = tf.keras.layers.concatenate([context, dropout_lstm_2])\n",
        "    dense_layer_1 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(EMBEDDING_DIM*4, activation='tanh' , kernel_regularizer=tf.keras.regularizers.l2(regularizer_coefficient)))\n",
        "    predicted_char_layer = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(len(characters), activation='softmax' , kernel_regularizer=tf.keras.regularizers.l2(regularizer_coefficient)))\n",
        "\n",
        "    dense_layer_output_1 = dense_layer_1(decoder_combined_context)\n",
        "    predicted_char = predicted_char_layer(dense_layer_output_1)\n",
        "    \n",
        "    Model = tf.keras.Model(inputs=[encoder_input, decoder_inputs, room_id_bit], outputs=[predicted_char])\n",
        "    # Model.summary()\n",
        "    tf.keras.utils.plot_model(Model, show_shapes=True, to_file='model.png')\n",
        "\n",
        "    'For reference, also prepared some tricks'\n",
        "    encoder_model = tf.keras.Model([encoder_input, room_id_bit], [encoder_states_1[0], encoder_states_1[1], encoder_states_2[0], encoder_states_2[1], enc_lstm2])\n",
        "    tf.keras.utils.plot_model(encoder_model, show_shapes=True, to_file='encoder_model.png')\n",
        "    \n",
        "    decoder_state_input_h = tf.keras.Input(shape=(EMBEDDING_DIM,))\n",
        "    decoder_state_input_c = tf.keras.Input(shape=(EMBEDDING_DIM,))\n",
        "    decoder_state_input_h1 = tf.keras.Input(shape=(EMBEDDING_DIM,))\n",
        "    decoder_state_input_c1 = tf.keras.Input(shape=(EMBEDDING_DIM,))\n",
        "    \n",
        "    'Add 2 for double room_id_inputs'\n",
        "    encoder_output_in = tf.keras.Input(shape=(context_vector_length + 2, EMBEDDING_DIM,))\n",
        "    decode_embedding = embedding_layer(decoder_inputs)\n",
        "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c, decoder_state_input_h1, decoder_state_input_c1]\n",
        "    d_o, state_h, state_c = lstm_1_layer(decode_embedding, initial_state=decoder_states_inputs[:2])\n",
        "    d_o, state_h1, state_c1 = lstm_2_layer(d_o, initial_state=decoder_states_inputs[-2:])\n",
        "    decoder_states = [state_h, state_c, state_h1, state_c1]\n",
        "\n",
        "    'try to add attention here~'\n",
        "    attention = tf.keras.layers.Dot(axes=[2, 2])([d_o, encoder_output_in])\n",
        "    attention = tf.keras.layers.Activation('softmax', name='attention')(attention)\n",
        "    context = tf.keras.layers.Dot(axes=[2, 1])([attention, encoder_output_in])\n",
        "    decoder_combined_context = tf.keras.layers.concatenate([context, d_o])\n",
        "\n",
        "    dense_layer_output_1 = dense_layer_1(decoder_combined_context)\n",
        "    decoder_outputs = predicted_char_layer(dense_layer_output_1)\n",
        "    decoder_model = tf.keras.Model([decoder_inputs] + decoder_states_inputs + [encoder_output_in], [decoder_outputs] + decoder_states)\n",
        "    tf.keras.utils.plot_model(decoder_model, show_shapes=True, to_file='decoder_model.png')\n",
        "\n",
        "    return Model, encoder_model, decoder_model\n",
        "\n",
        "def get_stand_alone_decoder(seq_len=30, context_length = context_vector_length, batch_size=None, stateful=True):\n",
        "    decoder_state_input_h = tf.keras.Input(shape=(EMBEDDING_DIM,))\n",
        "    decoder_state_input_c = tf.keras.Input(shape=(EMBEDDING_DIM,))\n",
        "    decoder_state_input_h1 = tf.keras.Input(shape=(EMBEDDING_DIM,))\n",
        "    decoder_state_input_c1 = tf.keras.Input(shape=(EMBEDDING_DIM,))\n",
        "    \n",
        "    decoder_inputs = tf.keras.Input(name='Decoder_input', shape=(seq_len,), batch_size=batch_size, dtype=tf.int32)\n",
        "    \n",
        "    'Add 2 for room_id_inputs'\n",
        "    encoder_output_in = tf.keras.Input(shape=(context_vector_length + 2, EMBEDDING_DIM,))\n",
        "\n",
        "    embedding_layer = tf.keras.layers.Embedding(input_dim=len(characters), output_dim=EMBEDDING_DIM, embeddings_initializer = tf.keras.initializers.Constant(embedding_matrix), trainable=False)\n",
        "    decode_embedding = embedding_layer(decoder_inputs)\n",
        "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c, decoder_state_input_h1, decoder_state_input_c1]\n",
        "    lstm_1_layer = tf.keras.layers.LSTM(EMBEDDING_DIM, name='decoder_lstm_1', stateful=stateful, return_state=True, return_sequences=True)\n",
        "    d_o, state_h, state_c = lstm_1_layer(decode_embedding, initial_state=decoder_states_inputs[:2])\n",
        "    lstm_2_layer = tf.keras.layers.LSTM(EMBEDDING_DIM, name='decoder_lstm_2', stateful=stateful, return_state=True, return_sequences=True)\n",
        "    d_o, state_h1, state_c1 = lstm_2_layer(d_o, initial_state=decoder_states_inputs[-2:])\n",
        "    decoder_states = [state_h, state_c, state_h1, state_c1]\n",
        "    \n",
        "    'try to add attention here~'\n",
        "    attention = tf.keras.layers.Dot(axes=[2, 2])([d_o, encoder_output_in])\n",
        "    attention = tf.keras.layers.Activation('softmax', name='attention')(attention)\n",
        "    context = tf.keras.layers.Dot(axes=[2, 1])([attention, encoder_output_in])\n",
        "    decoder_combined_context = tf.keras.layers.concatenate([context, d_o])\n",
        "    \n",
        "    dense_layer_1 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(EMBEDDING_DIM*4, activation='tanh'))\n",
        "    predicted_char_layer = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(len(characters), activation='softmax'))\n",
        "    \n",
        "    dense_layer_output_1 = dense_layer_1(decoder_combined_context)\n",
        "    decoder_outputs = predicted_char_layer(dense_layer_output_1)\n",
        "    decoder_model = tf.keras.Model([decoder_inputs] + decoder_states_inputs + [encoder_output_in], [decoder_outputs] + decoder_states)\n",
        "    tf.keras.utils.plot_model(decoder_model, show_shapes=True, to_file='decoder_model.png')\n",
        "    return decoder_model\n",
        "\n",
        "def step_decay(epoch):\n",
        "    import math\n",
        "    initial_lrate = 0.001\n",
        "    drop = 0.6\n",
        "    epochs_drop = 1.0\n",
        "    lrate = initial_lrate * math.pow(drop, math.floor((1 + epoch) / epochs_drop))\n",
        "    print(\"lrate: {}, epoch: {}\".format(lrate, epoch))\n",
        "    return lrate\n",
        "\n",
        "# training_model,encoder_model, decoder_model = lstm_model(seq_len=30, context_length = context_vector_length, stateful=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VzBYDJI0_Tfm"
      },
      "source": [
        "### Train the model\n",
        "\n",
        "First, we need to create a distribution strategy that can use the TPU. In this case it is TPUStrategy. You can create and compile the model inside its scope. Once that is done, future calls to the standard Keras methods `fit`, `evaluate` and `predict` use the TPU.\n",
        "\n",
        "Again note that we train with `stateful=False` because while training, we only care about one batch at a time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ExQ922tfzSGA",
        "outputId": "51b250bd-9f41-4a92-c15f-1a864b032527",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        }
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)\n",
        "tf.contrib.distribute.initialize_tpu_system(resolver)\n",
        "strategy = tf.contrib.distribute.TPUStrategy(resolver)\n",
        "\n",
        "with strategy.scope():\n",
        "  training_model,encoder_model, decoder_model = lstm_model(seq_len=30, context_length = context_vector_length, stateful=False)\n",
        "  lrate = tf.keras.callbacks.LearningRateScheduler(step_decay)\n",
        "  adam = tf.keras.optimizers.RMSprop(lr=0.0, decay=0.0)\n",
        "  # 'layer frozen'\n",
        "  # for layer in training_model.layers[:-1]:\n",
        "\t#   layer.trainable = False\n",
        "  training_model.compile(\n",
        "      # optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.01),\n",
        "      optimizer = 'adam',\n",
        "      loss='sparse_categorical_crossentropy',\n",
        "      metrics=['sparse_categorical_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Initializing the TPU system: 10.98.176.234:8470\n",
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.98.176.234:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 13823376781481859044)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 10440750302577450772)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 10705872899738057928)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 8933498303626144582)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 1855537440139721632)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 5630110625702430444)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 14284648454254130754)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2887412434783985957)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 7923455823826903371)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 12463799809955759435)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 4816588636339316079)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKIYptTySorJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training_model.load_weights('/tmp/bard_{}.h5'.format(0))\n",
        "  # 'load pretrained weights'\n",
        "# encoder_model.load_weights('encoder.h5')\n",
        "# decoder_model.load_weights('decoder.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvcIrF2LhkcP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir weights\n",
        "!mkdir models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec2YZwjojEye",
        "colab_type": "code",
        "outputId": "a40e7f1b-5ab2-4366-8ac1-1f34c001fc9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "training_model.fit(\n",
        "    input_fn(),\n",
        "    steps_per_epoch=50000,\n",
        "    epochs=1,\n",
        "    callbacks=[lrate]\n",
        ")\n",
        "saver_index = 0\n",
        "# training_model.save_weights('weights/bard_{}.h5'.format(saver_index), overwrite=True)\n",
        "\n",
        "# training_model.save('models/bard_{}.h5'.format(saver_index), overwrite=True)\n",
        "\n",
        "training_model.save('/tmp/bard_{}.js.h5'.format(saver_index), overwrite=True)\n",
        "saver_index += 100"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 29902401/29902401 [00:30<00:00, 979470.40it/s]\n",
            "180232680it [01:15, 2375810.17it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing the txt: Tensor(\"strided_slice:0\", shape=(20,), dtype=int32), with label: Tensor(\"strided_slice_1:0\", shape=(20,), dtype=int32)\n",
            "--- slice tensor spends: 0.004944801330566406 seconds ---\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "lrate: 0.0006, epoch: 0\n",
            "50000/50000 [==============================] - 13066s 261ms/step - loss: 2.6870 - sparse_categorical_accuracy: 0.5522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9u5RMcskyBH1",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbCoCVkX1MWu",
        "colab_type": "text"
      },
      "source": [
        "dropout 均为0.5时：\n",
        "loss: 2.2302， sparse_categorical_accuracy: 0.6051\n",
        "\n",
        "dropout 均为0.4时\n",
        "loss: 2.1744 - sparse_categorical_accuracy: 0.6124\n",
        "\n",
        "initial_lrate 为0.0002时\n",
        "\n",
        "loss: 2.3910 - sparse_categorical_accuracy: 0.5846"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wV3mrS_xjDgZ",
        "colab_type": "text"
      },
      "source": [
        "# 删除EOS 和\\n  &  分割 语句"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfXgJWGTjBd-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def delete_EOS(input: list) -> list:\n",
        "    while 'eos' in input:\n",
        "        input.remove('eos')\n",
        "    str1 = \"\".join(input)\n",
        "    res = str1.split('\\n')\n",
        "    del res[-1]\n",
        "    for single in res:\n",
        "      print(single)\n",
        "    return res  \n",
        "# print(delete_EOS(['eos', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '\\n', 'eos', '感谢', '观看', '\\n', 'eos', '8', '8', '8', '8', '8', '8', '8', '8', '\\n', 'eos', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '\\n', 'eos', '8', '8', '8', '8', '8', '8', '8', '8', '\\n', 'eos', '8', '8', '8', '8', '8', '\\n', 'eos', '感谢', '转播man', '\\n', 'eos', '8', '8', '8', '8', '8', '8', '8', '\\n', 'eos', '感谢', '转播man', '\\n', 'eos', 'a', 'n', 't', 'i', '路过', '，', '不用', '管', '\\n', 'eos', 'o', 'k', 'k', '\\n', 'eos', 'a', 'n', 't', 'i', '需要', '理由', '吗', '？', '\\n']\n",
        "# ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwiZBc6dmIzs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'get some real text inputs'\n",
        "import random\n",
        "import copy\n",
        "# preprocessed_TXT = '/content/new_filtered_data.json'\n",
        "def load_in_texts():\n",
        "  with open(preprocessed_TXT, encoding='UTF-8') as json_file:\n",
        "      data = json.load(json_file, encoding='UTF-8')\n",
        "      'process the data'\n",
        "      txt = []\n",
        "      label_part = []\n",
        "      for single_meg in tqdm(data):\n",
        "        single_meg[0].insert(0, 'eos')\n",
        "        single_meg[0].append('\\n')\n",
        "        label = [single_meg[1]] * len(single_meg[0])\n",
        "        txt.extend(single_meg[0])\n",
        "        label_part.extend(label)\n",
        "\n",
        "      'remove that does not belongs to characters...'\n",
        "      new_txt = []\n",
        "      new_label_part = []\n",
        "      for (single, label) in tqdm(zip(txt, label_part)):\n",
        "        if single not in  ['成雨', '効']:\n",
        "          new_txt.append(single)\n",
        "          new_label_part.append(label)\n",
        "      print(\"updated txt, remove from {} to {}, examples: {}\".format(len(txt), len(new_txt), new_txt[:20]))\n",
        "      return new_txt, new_label_part"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaQ7ymktLXek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encoder_model.save_weights('/content/drive/My Drive/encoder.h5')\n",
        "# decoder_model.save_weights('/content/drive/My Drive/decoder.h5')\n",
        "\n",
        "encoder_model.save_weights('/tmp/encoder.h5')\n",
        "decoder_model.save_weights('/tmp/decoder.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TCBtcpZkykSf"
      },
      "source": [
        "### Make predictions with the model\n",
        "\n",
        "Use the trained model to make predictions and generate your own fake danmaku messages.\n",
        "Start the model off with a *seed* sentence, then generate 250 characters from it. The model makes five predictions from the initial seed.\n",
        "\n",
        "The predictions are done on the CPU so the batch size (5) in this case does not have to be divisible by 8.\n",
        "\n",
        "Note that when we are doing predictions or, to be more precise, text generation, we set `stateful=True` so that the model's state is kept between batches. If stateful is false, the model state is reset between each batch, and the model will only be able to use the information from the current batch (a single character) to make a prediction.\n",
        "\n",
        "The output of the model is a set of probabilities for the next character (given the input so far). To build a paragraph, we predict one character at a time and sample a character (based on the probabilities provided by the model). For example, if the input character is \"草\" and the output probabilities are \"草\" (0.65), \"哈\" (0.30), others characters (0.05), then we allow our model to generate text other than just \"草\" and \"哈\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCzuRE6lLzUh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "6d734b4a-4ca7-4bc0-a824-78b48f86e557"
      },
      "source": [
        "!pip install pprint"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pprint\n",
            "  Downloading https://files.pythonhosted.org/packages/99/12/b6383259ef85c2b942ab9135f322c0dce83fdca8600d87122d2b0181451f/pprint-0.1.tar.gz\n",
            "Building wheels for collected packages: pprint\n",
            "  Building wheel for pprint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pprint: filename=pprint-0.1-cp36-none-any.whl size=1250 sha256=68d89039ed3a24f09f68d97a7bbb1bcb1e84b474d03f3925e5b367aeaa9a7cbd\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/d4/c6/16a6495aecc1bda5d5857bd036efd50617789ba9bea4a05124\n",
            "Successfully built pprint\n",
            "Installing collected packages: pprint\n",
            "Successfully installed pprint-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tU7M-EGGxR3E",
        "colab": {}
      },
      "source": [
        "# BATCH_SIZE = 2\n",
        "# PREDICT_LEN = 30\n",
        "# BEAM_SIZE = 10\n",
        "# import pprint\n",
        "# # Keras requires the batch size be specified ahead of time for stateful models.\n",
        "# # We use a sequence length of 1, as we will be feeding in one character at a \n",
        "# # time and predicting the next character.\n",
        "# # tf.keras.backend.clear_session()\n",
        "\n",
        "# _, encoder_model, _ = lstm_model(seq_len=1, batch_size=BATCH_SIZE, stateful=True)\n",
        "# # encoder_model.load_weights('/content/drive/My Drive/encoder.h5')\n",
        "# encoder_model.load_weights('/tmp/encoder.h5')\n",
        "\n",
        "# decoder_model = get_stand_alone_decoder(seq_len=1, batch_size=BATCH_SIZE, stateful=True)\n",
        "# # decoder_model.load_weights('/content/drive/My Drive/decoder.h5')\n",
        "# decoder_model.load_weights('/tmp/decoder.h5')\n",
        "\n",
        "# # We seed the model with our initial string, copied BATCH_SIZE times\n",
        "# # seed_txt = ['了', '\\n', 'eos', '再次', '坑', '乌拉', '\\n', 'eos', 'p', 'o', 'i', '和', '乌拉', '拉', '在', '一起', '打', '吗', '？', '\\n', 'eos', '马赛克', '！', '\\n', 'eos', '噗', '\\n', 'eos', 'e', 'm', 'm', 'm', '火车', '晚', '了', 'p', 'o', 'i', '\\n', 'eos', '？', '？', '？', '\\n', 'eos', '？', '？', '？', '\\n', 'eos', '你', '要', '知道', '我', '写', '过', '文', '\\n', 'eos', '咬', '滑稽', '\\n', 'eos', '这', '是', '一段', '有', '画面', '的', '文字', '\\n', 'eos', '污', '拉拉', '\\n', 'eos', '乌拉', '拉', '晚上', '好', '\\n', 'eos', '去', '拿', '对面', '油', '\\n', 'eos', '晚', '好', '吖', '\\n', 'eos', '哇', '，', '乌拉', '粉丝', '还有', '看', '高', '达', '的', '\\n', 'eos', '（', '6', '9', '）', '\\n', 'eos', '我', '怀疑', '你', '在', '开车', '\\n', 'eos', '尝试', '理解', 'p', 'o', 'i', '\\n', 'eos', '好多', '.', '。', '。', '。', '\\n', 'eos', '不要', '火车', 'p', 'o', 'i', '？', '\\n', 'eos', '上次', '。', '。', '。', '\\n', 'eos', '我', '看看', '我', '下', '个', 'c', 'o', 'h', '\\n', 'eos', '穿', '模', '\\n', 'eos', '？', '？', '？', '？', '？', '？', '？', '\\n', 'eos', '？', '？', '？', '？', '？', '？', '？', '？', '？', '？', '？', '？', '？', '？', '？', '？', '？', '？', '？', '？', '？', '？', '？', '？', '？', '？', '？', '？', '\\n', 'eos', '天狗', '\\n']\n",
        "# # seed_txt = ['eos','天', '狗','\\n']*200\n",
        "\n",
        "# print(\"Load in texts...\")\n",
        "# seed = transform(load_in_texts(100))\n",
        "# # print(seed_txt)\n",
        "\n",
        "# # seed = transform(load_in_texts(100))\n",
        "# seed = np.repeat(np.expand_dims(seed, 0), BATCH_SIZE, axis=0)\n",
        "# # Encode the input as state vectors.\n",
        "# state_and_output = encoder_model.predict(seed)\n",
        "# states_value = [state_and_output[:4]] * BEAM_SIZE\n",
        "# encoder_output = state_and_output[-1]\n",
        "\n",
        "# # Solve decoder things\n",
        "# last_predictions = [np.array([[7010]]*BATCH_SIZE, dtype=np.int32)]\n",
        "# # Beam serach impl!\n",
        "# 'at first, all prob is 0'\n",
        "# path_saver = [[0, list()]] * BEAM_SIZE\n",
        "# print(\"Preforming beam search...\")\n",
        "# for i in tqdm(range(PREDICT_LEN)):\n",
        "#   total_slot = []\n",
        "#   for beam_words_id in range(len(last_predictions)):\n",
        "#     'for this words'\n",
        "#     last_word = last_predictions[beam_words_id]\n",
        "#     next_probits, h, c, h1, c1 = decoder_model.predict([last_word] + states_value[beam_words_id] + [encoder_output])\n",
        "#     'assign right states value'\n",
        "#     if len(last_predictions) == 1:\n",
        "#       'at the beginning, just renew all the state values'\n",
        "#       for i in range(BEAM_SIZE):\n",
        "#         states_value[i] = [h, c, h1, c1]#######NOTICE THE ADDITIONAL HIDDEN STATES\n",
        "#     else:\n",
        "#       'if we have more choices, only update one'\n",
        "#       states_value[beam_words_id] = [h, c, h1, c1]#######NOTICE THE ADDITIONAL HIDDEN STATES\n",
        "#     batch_id = 0\n",
        "#     next_probits = next_probits[:, 0, :][batch_id]\n",
        "#     'for each batch'\n",
        "#     'just a dirty work around, since all batch return the same results'\n",
        "#     previous_prob = path_saver[beam_words_id]\n",
        "#     top_k_words = next_probits.argsort()[-BEAM_SIZE:]\n",
        "#     for words_id in top_k_words:\n",
        "#       total_slot.append([previous_prob[0] + np.log(next_probits[words_id]), previous_prob[1] + [words_id]])\n",
        "#   'sort by the first prob'\n",
        "#   path_saver = sorted(total_slot, key=lambda tup:tup[0])[-BEAM_SIZE:]\n",
        "#   last_predictions = []\n",
        "  \n",
        "#   'Do something to get last predictions work here'\n",
        "#   for previous_path_tuple in path_saver:\n",
        "#     last_path = previous_path_tuple[1][-1]\n",
        "#     last_predictions.append(np.array([[last_path]]*BATCH_SIZE, dtype=np.int32))\n",
        "\n",
        "# 'generate top k sentences'\n",
        "# fin_res = []\n",
        "# for single_path in path_saver:\n",
        "#   prob = single_path[0]\n",
        "#   sentence = []\n",
        "#   for val in single_path[1]:\n",
        "#     current_char = n_to_char[val]\n",
        "#     sentence.append(current_char)\n",
        "#     if current_char == '\\n':\n",
        "#       break\n",
        "#   generated_sentence = ''.join(sentence)  # Convert back to text\n",
        "#   fin_res.append([prob, generated_sentence])\n",
        "\n",
        "# fin_res = sorted(fin_res, key=lambda tup:tup[0])\n",
        "# pprint.pprint(fin_res)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9GdlJWwpaFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 500\n",
        "PREDICT_LEN = 15\n",
        "\n",
        "# Keras requires the batch size be specified ahead of time for stateful models.\n",
        "# We use a sequence length of 1, as we will be feeding in one character at a \n",
        "# time and predicting the next character.\n",
        "# tf.keras.backend.clear_session()\n",
        "\n",
        "_, encoder_model, _ = lstm_model(seq_len=1, batch_size=BATCH_SIZE, stateful=True)\n",
        "# prediction_model.load_weights('/tmp/bard_{}.h5'.format(0))\n",
        "encoder_model.load_weights('/tmp/encoder.h5')\n",
        "\n",
        "decoder_model = get_stand_alone_decoder(seq_len=1, batch_size=BATCH_SIZE, stateful=True)\n",
        "decoder_model.load_weights('/tmp/decoder.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etpePQVKpdRN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "0b3596b1-a4ad-4439-8d99-e7a5f145ea36"
      },
      "source": [
        "# We seed the model with our initial string, copied BATCH_SIZE times\n",
        "\n",
        "# seed_txt = ['那', '是', '你', '心态', '不行', '\\n', 'eos', '我', '爱', '酱', '真是', '越来越', '聪明', '啦', '？', '\\n', 'eos', '本子', '预定', '\\n', 'eos', '被', '吓', '到', '了', '\\n', 'eos', '哈哈哈', '哈哈哈', '\\n', 'eos', '吹', '\\n', 'eos', '字幕', '没错', '好', '吧', '\\n', 'eos', '代', '打', '当然', '是', '开玩笑', '，', '但是', '说', '多', '了', '是', '真的', '烦', '\\n', 'eos', '代', '打', '是', '不过', '分', '，', '但', '你', '一直', '刷', '，', '你', '不', '烦', '别人', '烦', '\\n', 'eos', '整个', '游戏', '就', '在', '这儿', '卡', '关', '了', '不', '知道', '可以', '跳', '2', '3', '3', '3', '\\n', 'eos', '1', '7', '秒', '\\n', 'eos', 'w', 'w', 'w', 'w']\n",
        "# seed_txt = ['嘛', '（', '清楚', '多', '意', '）', '\\n', 'eos', '完事', 'w', 'w', 'w', 'w', 'w', 'w', 'w', 'w', 'w', '\\n', 'eos', '很', '懂', '\\n', 'eos', '自己', '都', '笑', '了', '\\n', 'eos', 'w', 'w', 'w', 'w', 'w', 'w', 'w', 'w', 'w', 'w', 'w', 'w', 'w', 'w', 'w', 'w', 'w', '\\n', 'eos', 'w', 'w', 'w', 'w', 'w', 'w', 'w', 'w', '\\n', 'eos', '老鸨', '\\n', 'eos', '很', '懂', '。', '。', '。', '我', '第一次', '知道', '\\n', 'eos', 'j', 'k', '一周', '目', '草', '生', '\\n', 'eos', '过于', '清楚', '\\n', 'eos', '艾', '琳', '太', '真实', '了', '\\n', 'eos', '实在', '是', '过于', '清楚', '\\n', 'eos', '怎么', '知道', '的']\n",
        "# seed = transform(seed_txt)\n",
        "new_txt, new_label = load_in_texts()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 29902401/29902401 [00:36<00:00, 824817.69it/s]\n",
            "180232680it [01:12, 2477162.52it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "updated txt, remove from 180232680 to 180232680, examples: ['eos', '大米', '也', '回来', '了', '\\n', 'eos', '.', '\\n', 'eos', '待机', '\\n', 'eos', '待机', '\\n', 'eos', '来晚', '了', ' ', '来晚']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5lRIBiYY5_r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "defcda98-7e3f-4821-fc40-a11828636dca"
      },
      "source": [
        "len(n_to_char)\n",
        "# print(f\"10817: {n_to_char[-2]}\")\n",
        "# print(f\"10818: {n_to_char[-1]}\")\n",
        "print(n_to_char[10816])\n",
        "print(n_to_char[10817])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "eos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsU6mY624dad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clip_text(txt_length, new_txt, new_label, start_pos_type = 0):\n",
        "    proposed_start_index = new_label.index(start_pos_type)\n",
        "    'Currently, we only support 355 vtubers'\n",
        "    proposed_end_index = new_label.index(min(start_pos_type+1, 355))\n",
        "    start_index = random.randint(proposed_start_index, proposed_end_index - txt_length)\n",
        "    clipped_txt_for_test = new_txt[start_index:start_index + txt_length]\n",
        "    clipped_labels_for_test = new_label[start_index:start_index + txt_length]\n",
        "    delete_EOS(copy.deepcopy(clipped_txt_for_test))\n",
        "    return clipped_txt_for_test, clipped_labels_for_test[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_xfdSECt4yc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# room_id_mapping = '/content/room_id_mapping.json'\n",
        "# with open(room_id_mapping, encoding='UTF-8') as json_file:\n",
        "#       id_mapping_dict = json.load(json_file, encoding='UTF-8')\n",
        "# print(f\"mapping_id_res: {id_mapping_dict}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT4ZpIuhNYOQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4d1fddfc-c78c-4394-dad8-79487a6df7b9"
      },
      "source": [
        "print(\"Load in texts...\")\n",
        "'283：茯苓猫不黑'\n",
        "input_text, input_label = clip_text(100, new_txt, new_label, start_pos_type=70)\n",
        "# print(\"the previous text is from: {}\".format(id_mapping_dict[str(input_label)]))\n",
        "seed = transform(input_text)\n",
        "print(\"generating text...\")\n",
        "seed = np.repeat(np.expand_dims(seed, 0), BATCH_SIZE, axis=0)\n",
        "label_seed = np.repeat(np.expand_dims(input_label, 0), BATCH_SIZE, axis=0)\n",
        "state_and_output = encoder_model.predict((seed, label_seed))\n",
        "states_value = state_and_output[:4]\n",
        "encoder_output = state_and_output[-1]\n",
        "# Solve decoder things, we just happen to have 10817 tokens here \n",
        "predictions = [np.array([[10817]]*BATCH_SIZE, dtype=np.int32)]\n",
        "predictions_prob = []\n",
        "for i in range(PREDICT_LEN):\n",
        "  last_word = predictions[-1]\n",
        "  next_probits, h, c, h1, c1 = decoder_model.predict([last_word] + states_value + [encoder_output])\n",
        "  next_probits = next_probits[:, 0, :]\n",
        "  # sample from our output distribution\n",
        "  next_idx = [\n",
        "      np.random.choice(len(characters), p=next_probits[i])\n",
        "      # np.argmax(next_probits[i])\n",
        "      for i in range(BATCH_SIZE)\n",
        "  ]\n",
        "  'build the prob case'\n",
        "  prob = []\n",
        "  for batch_id in range(BATCH_SIZE):\n",
        "    prob.append(next_probits[batch_id][next_idx[batch_id]])\n",
        "  predictions_prob.append(np.asarray(prob))\n",
        "  predictions.append(np.asarray(next_idx, dtype=np.int32))\n",
        "  # Update states\n",
        "  states_value = [h, c, h1, c1]#######NOTICE THE ADDITIONAL HIDDEN STATES\n",
        "\n",
        "generated_whole_list = []\n",
        "for i in range(BATCH_SIZE):\n",
        "  # print('PREDICTION %d\\n\\n' % i)\n",
        "  p = [predictions[j][i] for j in range(PREDICT_LEN)]\n",
        "  p_prob = [predictions_prob[j][i] for j in range(PREDICT_LEN)]\n",
        "  current_list = []\n",
        "  'one sentence for one batch'\n",
        "  this_batch_prob = 0.\n",
        "  for index in range(len(p)):\n",
        "    'just get the character generated'\n",
        "    val = p[index]\n",
        "    cur_prob = np.log(p_prob[index])\n",
        "    if index == 0:\n",
        "      val = val[0]\n",
        "    current_char = n_to_char[val]\n",
        "    current_list.append(current_char)\n",
        "    this_batch_prob += cur_prob\n",
        "    if current_char == '\\n':\n",
        "      break\n",
        "  'we also wanna the average prob here'\n",
        "  this_batch_prob/=len(current_list)\n",
        "  current_list.remove('eos')\n",
        "  generated = ''.join(current_list)  # Convert back to text\n",
        "  if generated != '\\n':\n",
        "    generated_whole_list.append([this_batch_prob, generated])\n",
        "fin_res = sorted(generated_whole_list, key=lambda tup:tup[0], reverse=True)\n",
        "\n",
        "for this_batch_prob, generated in fin_res:\n",
        "  print(\"with prob: {}, generated: {}\".format(this_batch_prob, generated))\n",
        "# assert len(generated) == PREDICT_LEN, 'Generated text too short'"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load in texts...\n",
            "\\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\\花丸/\\花丸/\\花丸/\\花丸/\\花丸/\\花丸/\n",
            "ｋｋｓｋ\n",
            "花丸最高\n",
            "\\花丸/\\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\\花丸/\\花丸/\\花丸/\\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\\花丸/\\花丸/\\花丸/\\花丸/\\花丸/\n",
            "generating text...\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845086745248409, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845087539977006, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.05845088049100013, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.058450883967937746, generated: \\花丸/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.1942320563076854, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.1942320563076854, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.1942320563076854, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.1942320563076854, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.1942320563076854, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.1942320563076854, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.1942320563076854, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.1942320563076854, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.1942320563076854, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.19423206482263464, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.19423206482263464, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.19423206482263464, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.19423206482263464, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.19423206482263464, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.19423206482263464, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.19423206482263464, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.19423207347062998, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.19423207347062998, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.19423207347062998, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.19423207347062998, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.19423207347062998, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.19423207347062998, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.19423207347062998, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.19423207347062998, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.19423207347062998, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.19423207347062998, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.19423207347062998, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.19423207347062998, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.19423208251776355, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.19423208251776355, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.19423208251776355, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.19423208251776355, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.19423208251776355, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.19423208251776355, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.19423208251776355, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.19423208251776355, generated: \\花丸/\\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.24201455770750424, generated: ＼花丸／＼花丸／＼花丸／＼花丸／＼花丸\n",
            "with prob: -0.24201455770750424, generated: ＼花丸／＼花丸／＼花丸／＼花丸／＼花丸\n",
            "with prob: -0.24201455770750424, generated: ＼花丸／＼花丸／＼花丸／＼花丸／＼花丸\n",
            "with prob: -0.24201455770750424, generated: ＼花丸／＼花丸／＼花丸／＼花丸／＼花丸\n",
            "with prob: -0.24201455770750424, generated: ＼花丸／＼花丸／＼花丸／＼花丸／＼花丸\n",
            "with prob: -0.24201455770750424, generated: ＼花丸／＼花丸／＼花丸／＼花丸／＼花丸\n",
            "with prob: -0.24201455770750424, generated: ＼花丸／＼花丸／＼花丸／＼花丸／＼花丸\n",
            "with prob: -0.24201456571687838, generated: ＼花丸／＼花丸／＼花丸／＼花丸／＼花丸\n",
            "with prob: -0.24201456571687838, generated: ＼花丸／＼花丸／＼花丸／＼花丸／＼花丸\n",
            "with prob: -0.24201456571687838, generated: ＼花丸／＼花丸／＼花丸／＼花丸／＼花丸\n",
            "with prob: -0.24201456571687838, generated: ＼花丸／＼花丸／＼花丸／＼花丸／＼花丸\n",
            "with prob: -0.24201456571687838, generated: ＼花丸／＼花丸／＼花丸／＼花丸／＼花丸\n",
            "with prob: -0.24201457763780734, generated: ＼花丸／＼花丸／＼花丸／＼花丸／＼花丸\n",
            "with prob: -0.24201457763780734, generated: ＼花丸／＼花丸／＼花丸／＼花丸／＼花丸\n",
            "with prob: -0.24201457763780734, generated: ＼花丸／＼花丸／＼花丸／＼花丸／＼花丸\n",
            "with prob: -0.24201457763780734, generated: ＼花丸／＼花丸／＼花丸／＼花丸／＼花丸\n",
            "with prob: -0.24201457763780734, generated: ＼花丸／＼花丸／＼花丸／＼花丸／＼花丸\n",
            "with prob: -0.28463770695937757, generated: \\はれる/\\はれる/\\はれる\n",
            "with prob: -0.28463770695937757, generated: \\はれる/\\はれる/\\はれる\n",
            "with prob: -0.28463770695937757, generated: \\はれる/\\はれる/\\はれる\n",
            "with prob: -0.28463770695937757, generated: \\はれる/\\はれる/\\はれる\n",
            "with prob: -0.28463770695937757, generated: \\はれる/\\はれる/\\はれる\n",
            "with prob: -0.32262512609207383, generated: \\ 花丸 /\\ 花丸 /\\ 花丸 \n",
            "with prob: -0.32262513304594903, generated: \\ 花丸 /\\ 花丸 /\\ 花丸 \n",
            "with prob: -0.32262513304594903, generated: \\ 花丸 /\\ 花丸 /\\ 花丸 \n",
            "with prob: -0.32262514310423285, generated: \\ 花丸 /\\ 花丸 /\\ 花丸 \n",
            "with prob: -0.323360690944052, generated:  \\花丸/\\花丸/\\花丸/\\花丸/\\\n",
            "with prob: -0.323360690944052, generated:  \\花丸/\\花丸/\\花丸/\\花丸/\\\n",
            "with prob: -0.3233606959111057, generated:  \\花丸/\\花丸/\\花丸/\\花丸/\\\n",
            "with prob: -0.32336070832874003, generated:  \\花丸/\\花丸/\\花丸/\\花丸/\\\n",
            "with prob: -0.3427630022090549, generated: \\はい/\\はい/\\はい/\\は\n",
            "with prob: -0.3427630061826979, generated: \\はい/\\はい/\\はい/\\は\n",
            "with prob: -0.3427630061826979, generated: \\はい/\\はい/\\はい/\\は\n",
            "with prob: -0.34316176689886063, generated: \\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.34316176689886063, generated: \\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.34316176689886063, generated: \\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.34316176689886063, generated: \\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.34316177773606876, generated: \\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.34316177773606876, generated: \\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.34316177773606876, generated: \\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.34316177773606876, generated: \\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.34316177773606876, generated: \\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.34316177790540014, generated: \\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.34316177790540014, generated: \\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.34316177790540014, generated: \\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.34316177790540014, generated: \\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.34316177790540014, generated: \\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.34316177790540014, generated: \\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.34316177790540014, generated: \\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.34316177790540014, generated: \\花丸/\\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.35163146093097264, generated: ＼(^o^)／＼(^o^)／\n",
            "with prob: -0.3516314768255446, generated: ＼(^o^)／＼(^o^)／\n",
            "with prob: -0.3758842720857111, generated: ＼花丸／＼花丸／＼花丸／＼花丸／\n",
            "\n",
            "with prob: -0.3758842720857111, generated: ＼花丸／＼花丸／＼花丸／＼花丸／\n",
            "\n",
            "with prob: -0.3758842720857111, generated: ＼花丸／＼花丸／＼花丸／＼花丸／\n",
            "\n",
            "with prob: -0.37588428066718343, generated: ＼花丸／＼花丸／＼花丸／＼花丸／\n",
            "\n",
            "with prob: -0.37994514911462407, generated: \\花丸/ \\花丸/ \\花丸/\n",
            "\n",
            "with prob: -0.37994514911462407, generated: \\花丸/ \\花丸/ \\花丸/\n",
            "\n",
            "with prob: -0.37994514911462407, generated: \\花丸/ \\花丸/ \\花丸/\n",
            "\n",
            "with prob: -0.37994514911462407, generated: \\花丸/ \\花丸/ \\花丸/\n",
            "\n",
            "with prob: -0.3799451857944055, generated: \\花丸/ \\花丸/ \\花丸/\n",
            "\n",
            "with prob: -0.3799451857944055, generated: \\花丸/ \\花丸/ \\花丸/\n",
            "\n",
            "with prob: -0.38714411507149077, generated: ＼♥♥♥♥♥♥♥♥♥／\n",
            "\n",
            "with prob: -0.40421519429300956, generated: ε=ε=(ノ≧∇≦)ノ\n",
            "\n",
            "with prob: -0.40421520117046855, generated: ε=ε=(ノ≧∇≦)ノ\n",
            "\n",
            "with prob: -0.40421520117046855, generated: ε=ε=(ノ≧∇≦)ノ\n",
            "\n",
            "with prob: -0.4094060437541235, generated: ＼♥♥♥♥♥♥♥♥♥♥／\n",
            "\n",
            "with prob: -0.41520997001714854, generated: ε=ε=(ノ≧∇≦)ノε=ε\n",
            "with prob: -0.4159271149119983, generated: ＼はれる/＼はれる/＼はれる\n",
            "with prob: -0.4427154137008204, generated: ＼♥♥♥♥♥♥♥♥♥♥/\n",
            "\n",
            "with prob: -0.4618156059852316, generated: ＼花丸／＼花丸／＼花丸／\n",
            "\n",
            "with prob: -0.4618156385815217, generated: ＼花丸／＼花丸／＼花丸／\n",
            "\n",
            "with prob: -0.4786739884177223, generated: \\花/\\丸/\\花/\\丸/\\花\n",
            "with prob: -0.505362299340201, generated: ハィハィハィハィハィ\n",
            "\n",
            "with prob: -0.5116103659716568, generated: ハイ！ハイ！ハイ！ハイ！\n",
            "\n",
            "with prob: -0.5337333261345824, generated: \\ハイ/\\ハイ/\\ハイ/\\ハ\n",
            "with prob: -0.5337333261345824, generated: \\ハイ/\\ハイ/\\ハイ/\\ハ\n",
            "with prob: -0.5368590797527228, generated: (⌒▽⌒)(⌒▽⌒)(⌒▽⌒\n",
            "with prob: -0.5719709405753141, generated: \\花丸/\\小东/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.5926736611155017, generated: \\花丸/\\花丸/\\花丸/\\小東/\\花丸\n",
            "with prob: -0.6170159936804945, generated: \\花丸/\\花丸/\\花丸/\\小东/\\花丸\n",
            "with prob: -0.619398513084161, generated: \\花丸/\\鹿乃/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.6296733824298069, generated: ☀️☀️☀️☀️☀️☀️☀️\n",
            "with prob: -0.6328895978149376, generated: \\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.6328895978149376, generated: \\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.6328896127160988, generated: \\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.6328896129489294, generated: \\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.6328896129489294, generated: \\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.6328896129489294, generated: \\花丸/\\花丸/\n",
            "\n",
            "with prob: -0.6358067648330082, generated: \\はやい/\\はい/\\はい/\\\n",
            "with prob: -0.6457130157631279, generated: \\ちょこ/\\ちょこ/\\ちょこ\n",
            "with prob: -0.6548197380475661, generated: \\ののの/\\はれる/\\はれる\n",
            "with prob: -0.6847721736038996, generated: \\ccm/\\花丸/\\花丸/\\花丸/\\花丸\n",
            "with prob: -0.6848865008105349, generated: 哔哩哔哩(゜-゜)つロ干杯~\n",
            "\n",
            "with prob: -0.7040284964217184, generated: \\はれれ/\\はれる/\\はれる\n",
            "with prob: -0.7167499044948878, generated: \\花の丸/\\花の花/\\花の花\n",
            "with prob: -0.7442407512002815, generated: \\ccsk/\\ccsk/\\ccsk/\n",
            "\n",
            "with prob: -0.7446755130243089, generated: かわいいいいいいいいいい\n",
            "\n",
            "with prob: -0.7451422822060219, generated: ☀️🎵☀️🎵☀️🎵☀️🎵☀️\n",
            "with prob: -0.7501623727846891, generated: \\はな/\\はれ/\\はな/\\は\n",
            "with prob: -0.7693531890055358, generated: ＼❀♥❀♥❀♥❀♥❀♥❀／\n",
            "\n",
            "with prob: -0.7792784996547653, generated: ✧٩(ˊωˋ*)و✧\n",
            "\n",
            "with prob: -0.7808480746938254, generated: はい！はい！はい！\n",
            "\n",
            "with prob: -0.791898248122834, generated: (=・ω・=)\n",
            "\n",
            "with prob: -0.8146581977295378, generated: かわいい\n",
            "\n",
            "with prob: -0.8146581977295378, generated: かわいい\n",
            "\n",
            "with prob: -0.8146581977295378, generated: かわいい\n",
            "\n",
            "with prob: -0.8146582076636454, generated: かわいい\n",
            "\n",
            "with prob: -0.8146582076636454, generated: かわいい\n",
            "\n",
            "with prob: -0.8313856383460503, generated: (●'◡'●)ﾉ❤\n",
            "\n",
            "with prob: -0.850633025324593, generated: ❤☀❤☀❤☀❤☀❤☀\n",
            "\n",
            "with prob: -0.853053709336867, generated: ＼❤❤❤❤❤❤❤❤／\n",
            "\n",
            "with prob: -0.8737170876785447, generated: ハッピーシンセサイザー！\n",
            "\n",
            "with prob: -0.8781021288992964, generated: ❀花丸❀花丸❀花丸❀花丸❀\n",
            "\n",
            "with prob: -0.8835930947917707, generated: \\ ^O^/\\^O^/\\^O\n",
            "with prob: -0.9682098429029187, generated: \\は /\\はい/ \\はい/\n",
            "\n",
            "with prob: -0.9709604942306344, generated: かっこいい\n",
            "\n",
            "with prob: -0.970960511260533, generated: かっこいい\n",
            "\n",
            "with prob: -0.9906371445170711, generated: (｡･ω･｡)\n",
            "\n",
            "with prob: -1.0115726408238213, generated: \\はあ/\\はあ/\\はあ/\\は\n",
            "with prob: -1.0125332814951737, generated: \\ \\\\ / \\ \\ /\\ \n",
            "with prob: -1.0156377366627567, generated: \\光るなら/\\はれる/\\はれ\n",
            "with prob: -1.093311513774097, generated: ！！！！！！\n",
            "\n",
            "with prob: -1.0956745254927682, generated: (￣3￣)(￣3￣)\n",
            "\n",
            "with prob: -1.1530469476245344, generated: かわいいですね。\n",
            "\n",
            "with prob: -1.2270086721148497, generated: ＼ ♥^♥ ♥ ♥ ♥ ♥\n",
            "\n",
            "with prob: -1.231160170226758, generated: (▔□▔)/\n",
            "\n",
            "with prob: -1.2553718915830057, generated: kksk\n",
            "\n",
            "with prob: -1.2553718915830057, generated: kksk\n",
            "\n",
            "with prob: -1.2553718915830057, generated: kksk\n",
            "\n",
            "with prob: -1.2553718915830057, generated: kksk\n",
            "\n",
            "with prob: -1.2553718915830057, generated: kksk\n",
            "\n",
            "with prob: -1.2553718915830057, generated: kksk\n",
            "\n",
            "with prob: -1.255371932561199, generated: kksk\n",
            "\n",
            "with prob: -1.255371932561199, generated: kksk\n",
            "\n",
            "with prob: -1.255371932561199, generated: kksk\n",
            "\n",
            "with prob: -1.255371932561199, generated: kksk\n",
            "\n",
            "with prob: -1.255371932561199, generated: kksk\n",
            "\n",
            "with prob: -1.3149465546011925, generated: 花丸最高\n",
            "\n",
            "with prob: -1.3149465546011925, generated: 花丸最高\n",
            "\n",
            "with prob: -1.3149465695023537, generated: 花丸最高\n",
            "\n",
            "with prob: -1.3149465918540955, generated: 花丸最高\n",
            "\n",
            "with prob: -1.3149465918540955, generated: 花丸最高\n",
            "\n",
            "with prob: -1.3149466216564178, generated: 花丸最高\n",
            "\n",
            "with prob: -1.3149466216564178, generated: 花丸最高\n",
            "\n",
            "with prob: -1.3197317641291495, generated: ここ好き\n",
            "\n",
            "with prob: -1.31973177157973, generated: ここ好き\n",
            "\n",
            "with prob: -1.3281364542238103, generated:  \\花\\丸/\\ 花/\\ 花/\n",
            "with prob: -1.3318668137201004, generated: ❤花丸❤花丸❤花丸❤\n",
            "\n",
            "with prob: -1.332901647502543, generated: (≧∇≦)b(≧∇≦)v(≧\n",
            "with prob: -1.3534725103527308, generated: awsl\n",
            "\n",
            "with prob: -1.3534725103527308, generated: awsl\n",
            "\n",
            "with prob: -1.3534725103527308, generated: awsl\n",
            "\n",
            "with prob: -1.3676125371969343, generated: \\はれる/\\はれる/\\れる!\n",
            "with prob: -1.4274306622464792, generated: にゃにゃにゃ\n",
            "\n",
            "with prob: -1.4794243931246456, generated: いい感じ\n",
            "\n",
            "with prob: -1.488506142024259, generated: 太好听了╮(￣▽￣)╭\n",
            "\n",
            "with prob: -1.4889634667818124, generated: \\のこ姫/\\ここみ/\\ここみ\n",
            "with prob: -1.4932616092264652, generated: うまい\n",
            "\n",
            "with prob: -1.5353834557213955, generated: \\花丸suki/\\花丸花丸/\\花丸\\/\n",
            "\n",
            "with prob: -1.5442452728748322, generated: 花丸最高！！\n",
            "\n",
            "with prob: -1.549167013913393, generated: 頑張って\n",
            "\n",
            "with prob: -1.5727631151365737, generated: だあああああああああああすき\n",
            "with prob: -1.5787016168236732, generated: ！！！\n",
            "\n",
            "with prob: -1.5870165793166962, generated: かっこいい歌声\n",
            "\n",
            "with prob: -1.6083589937275975, generated: 哔哩哔哩干杯\n",
            "\n",
            "with prob: -1.6434120585521061, generated: 花丸！！！\n",
            "\n",
            "with prob: -1.6962080389261245, generated: いいね\n",
            "\n",
            "with prob: -1.7055714172311127, generated: \\ハリス/\\ハカチ\n",
            "\n",
            "with prob: -1.7147099481662735, generated: 刻在dna里的歌\n",
            "\n",
            "with prob: -1.7239340543746948, generated: suki\n",
            "\n",
            "with prob: -1.7239340543746948, generated: suki\n",
            "\n",
            "with prob: -1.757976682091664, generated: 私はとてもすごく良いです\n",
            "\n",
            "with prob: -1.7721975333988667, generated: 好き\n",
            "\n",
            "with prob: -1.7721975333988667, generated: 好き\n",
            "\n",
            "with prob: -1.815243407178463, generated: 花丸声がかわいい\n",
            "\n",
            "with prob: -1.8286962596078713, generated: 喵喵喵？\n",
            "\n",
            "with prob: -1.8624399900436401, generated: 上手\n",
            "\n",
            "with prob: -1.8957968175411224, generated: ｗｗｗ\n",
            "\n",
            "with prob: -1.9448225535452366, generated: エモいな\n",
            "\n",
            "with prob: -1.9542111486196518, generated: \\ no.1 / \\ 4 / \\ \n",
            "with prob: -1.9608392913360149, generated: あぁああああ\n",
            "\n",
            "with prob: -1.9770340859889983, generated: 雪の華\n",
            "\n",
            "with prob: -1.9834758784208033, generated: 歌があります。\n",
            "\n",
            "with prob: -2.001635887970527, generated: \\かの/\n",
            "\n",
            "with prob: -2.0136287858088813, generated: 草\n",
            "\n",
            "with prob: -2.05724455298235, generated: \\は守り/\\ありす/\\はな/\n",
            "with prob: -2.062159546961387, generated: KKSK\n",
            "\n",
            "with prob: -2.0875168705824763, generated: 大好き\n",
            "\n",
            "with prob: -2.164735563631569, generated: 泪 冲出来了\n",
            "\n",
            "with prob: -2.174500234425068, generated: 晚上好\n",
            "\n",
            "with prob: -2.2001224529760126, generated: ハッピークニヤン \n",
            "\n",
            "with prob: -2.2063324451446533, generated: 好听\n",
            "\n",
            "with prob: -2.2063324451446533, generated: 好听\n",
            "\n",
            "with prob: -2.2730281203985214, generated: kksk！\n",
            "\n",
            "with prob: -2.278952201207479, generated: tql\n",
            "\n",
            "with prob: -2.28589274858435, generated: www\n",
            "\n",
            "with prob: -2.4453989267349243, generated: 强\n",
            "\n",
            "with prob: -2.497332441806793, generated: 晚上好啊\n",
            "\n",
            "with prob: -2.50226072371006, generated: 口胡好评\n",
            "\n",
            "with prob: -2.5180061906576157, generated: あっ\n",
            "\n",
            "with prob: -2.5307204325993857, generated: はな！！\n",
            "\n",
            "with prob: -2.591546529904008, generated: 舒服了\n",
            "\n",
            "with prob: -2.615178557112813, generated: 66666666\n",
            "\n",
            "with prob: -2.620887368917465, generated: ほんとうがんう\n",
            "\n",
            "with prob: -2.689464408904314, generated: ><\n",
            "\n",
            "with prob: -2.730986401438713, generated: 听歌听歌\n",
            "\n",
            "with prob: -2.7402248435343304, generated: 66666666666666\n",
            "\n",
            "with prob: -2.8951241268465915, generated: 888888\n",
            "\n",
            "with prob: -2.8986828277508416, generated: 大佬们好哦\n",
            "\n",
            "with prob: -2.9296987976878883, generated: \\alice/\n",
            "\n",
            "with prob: -3.118983427683512, generated: 花丸大！！\n",
            "\n",
            "with prob: -3.195080711195866, generated: 感動的要死了\n",
            "\n",
            "with prob: -3.195297802488009, generated: 要开播了吗\n",
            "\n",
            "with prob: -3.2217144891619682, generated: bilibili最高\n",
            "\n",
            "with prob: -3.250593582789103, generated: 1\n",
            "\n",
            "with prob: -3.2823944561183453, generated: メルトシカゲロウ\n",
            "\n",
            "with prob: -3.3088625848293303, generated: 快乐的快乐\n",
            "\n",
            "with prob: -3.3672401309013367, generated: 无火大佬\n",
            "\n",
            "with prob: -3.381428096975599, generated: 動き きた\n",
            "\n",
            "with prob: -3.3952078024546304, generated: ?\n",
            "\n",
            "with prob: -3.400793232023716, generated: mea最高\n",
            "\n",
            "with prob: -3.4160290241241453, generated: 15小时了\n",
            "\n",
            "with prob: -3.4357214868068695, generated: 花丸厉害\n",
            "\n",
            "with prob: -3.469182252883911, generated: 感動\n",
            "\n",
            "with prob: -3.626995231424059, generated: bilibili world 音乐\n",
            "\n",
            "with prob: -3.646836052338282, generated: (来るは)いますから\n",
            "\n",
            "with prob: -3.7106966972351074, generated: ↑\n",
            "\n",
            "with prob: -3.8380207312958583, generated: 老人会,不懂\n",
            "\n",
            "with prob: -3.840891738732656, generated: ひぇあんあ来る\n",
            "\n",
            "with prob: -3.954732383135706, generated: 坐等awsl\n",
            "\n",
            "with prob: -3.970383862654368, generated: rua\n",
            "\n",
            "with prob: -4.16316915055116, generated: 青の天使？\n",
            "\n",
            "with prob: -4.177164793014526, generated: 这个真的\n",
            "\n",
            "with prob: -4.211833159128825, generated: 少年\n",
            "\n",
            "with prob: -4.306119203567505, generated: 涙\n",
            "\n",
            "with prob: -4.417579483985901, generated: 提前关注下\n",
            "\n",
            "with prob: -4.52698673804601, generated: 叶叶，这么可爱\n",
            "\n",
            "with prob: -4.5991805245478945, generated: 谁愣着..\n",
            "\n",
            "with prob: -4.612239874899387, generated: 合唱啊\n",
            "\n",
            "with prob: -4.622523331642151, generated: 风格最清晰\n",
            "\n",
            "with prob: -4.659744888544083, generated: 啃老婆！\n",
            "\n",
            "with prob: -4.680959701538086, generated: 大只\n",
            "\n",
            "with prob: -5.218937388488224, generated: 而且会唱日语自律\n",
            "\n",
            "with prob: -5.305891245603561, generated: 被迫上播\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWsSJRL4-4Eb",
        "colab_type": "text"
      },
      "source": [
        "####Get the generated data & origin data for comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaWYpM7u-2W9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "02bd74fe-896f-4c3a-fb48-2835cd037b99"
      },
      "source": [
        "origin_whole_list = []\n",
        "\n",
        "'get some origin data in a list'\n",
        "with open(preprocessed_TXT, encoding='UTF-8') as json_file:\n",
        "    data = json.load(json_file, encoding='UTF-8')\n",
        "\n",
        "'randomly sample some data from the list'\n",
        "index_range = np.arange(len(data))\n",
        "np.random.shuffle(index_range)\n",
        "\n",
        "'obtain the data'\n",
        "for index in range(PREDICT_LEN):\n",
        "  origin_data = ''.join(data[index_range[index]])\n",
        "  origin_whole_list.append(origin_data)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-7fa0b340f5e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m'obtain the data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPREDICT_LEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0morigin_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0morigin_whole_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, list found"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idBZ5easAlr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"real_message samples: {}\".format(origin_whole_list[:5]))\n",
        "print(\"fake_messages samples: {}\".format(generated_whole_list[:5]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKzuCc9LA6vV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'with pandas data frame'\n",
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "df = pd.DataFrame(columns=['message', 'label'])\n",
        "for origin in origin_whole_list:\n",
        "  df = df.append({'message': origin, 'label': 1}, ignore_index=True)\n",
        "for fake in generated_whole_list:\n",
        "  df = df.append({'message': fake, 'label': 0}, ignore_index=True)\n",
        "df = shuffle(df)\n",
        "df.to_csv(\"/content/fake_danmaku_evaluation.csv\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2a5cGsSTEBQD"
      },
      "source": [
        "## What's next\n",
        "\n",
        "* Danmaku-caption: generate danmaku based on context\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oL73nQwIO5yO",
        "colab_type": "text"
      },
      "source": [
        "### For TS-Javascript\n",
        "Load and save"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPIYk5gTO3Ay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prediction_model = lstm_model(seq_len=1,batch_size=8, stateful=True)\n",
        "# prediction_model.load_weights('/tmp/bard_{}.h5'.format(0))\n",
        "# prediction_model.save('/tmp/bard.js.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}