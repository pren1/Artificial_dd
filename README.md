# Artificial_dd

[![Generic badge](https://img.shields.io/badge/Tensorflow-keras-<COLOR>.svg)](https://shields.io/) 
[![Generic badge](https://img.shields.io/badge/github-dd_center-<COLOR>.svg)](https://shields.io/)
[![Generic badge](https://img.shields.io/badge/Beam-search-<COLOR>.svg)](https://shields.io/)
<p>
    <img src="model_picture/dd_center.png"/>
</p>

### âš ï¸ Notification

Please keep this repo **private**, and please notice that this is **not** an open-source software currently. 

### ğŸŒ² Request Packages

[![Generic badge](https://img.shields.io/badge/gdown-<COLOR>.svg)](https://shields.io/)
[![Generic badge](https://img.shields.io/badge/keras-<COLOR>.svg)](https://shields.io/)
[![Generic badge](https://img.shields.io/badge/numpy-<COLOR>.svg)](https://shields.io/)
[![Generic badge](https://img.shields.io/badge/scipy-<COLOR>.svg)](https://shields.io/)
[![Generic badge](https://img.shields.io/badge/tqdm-<COLOR>.svg)](https://shields.io/)
[![Generic badge](https://img.shields.io/badge/jieba-<COLOR>.svg)](https://shields.io/)
[![Generic badge](https://img.shields.io/badge/flask-<COLOR>.svg)](https://shields.io/)

### ğŸ“ƒ Introduction

A software that can send context-based fake danmaku. 

Please write more things here if any of you want to describe this project...

### â˜ï¸ Model structure

This is a sequence-to-sequence model with an attention mechanism. The encoder is used to compress the information in input messages, and the decoder is responsible for generating new texts based on the inputs. Here is the model structure:

<p>
    <img src="model_picture/model.png"/>
</p>

### âš“ï¸ Utilization

1. Run the following command, and you should see two folders named 'content' and 'tmp'.
```
bash ./download_sources.sh
```
2. Then, run:
```
python3 model_process.py
```
3. After that, post a message to http://10.0.0.207:5000/ in the following format:
```json
{"message":"kusoå’Œå¤å“¥æ’è½¦äº†, 2333333333, å“ˆå“ˆå“ˆå“ˆå“ˆå“ˆ, å“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆ"}
```
The python program should respond:
```
{
    "result": "not enough input messages"
}
```
However, if you send enough inputs, the program will return the generated messages:
```json
{
    "result": [
        "å“ˆå“ˆå“ˆå“ˆå“ˆ\n",
        "å‚»æ°”æº¢å‡ºå±å¹•\n",
        "666666666\n",
        "å“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆ\n",
        "å‚»ç´«è¯´çš„å¥½...\n",
        "åŸå£°æ˜¯poyyyå§ï¼ˆç¬‘ï¼‰\n",
        "awsl\n",
        "è‰\n",
        "å“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆ\n",
        "å‰æ–¹é«˜èƒ½\n",
        "å“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆ\n",
        "æˆ‘å¥½å‚»å•Š\n",
        "å“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆ\n",
        "23333333333333",
        "88888888888888",
        "è‰\n",
        "????????????\n",
        "è¦æ¥äº†\n",
        "æ¬§å°¼é…±è´´è´´\n",
        "å¥½çœŸå®...\n",
        "è¿‡äºæ²™é›•\n",
        "awsl\n",
        "å¥½å‰å®³çš„bgm23333333",
        "kksk\n",
        "å¥½ç³Ÿç³•çš„æ ·å­å•Š\n",
        "å‚»æ°”æº¢å‡ºå±å¹•\n",
        "awsl\n",
        "awsl\n",
        "666666666\n",
        "23333333333333",
        "è‰\n",
        "awsl\n",
        "å¥½ä¼šhero2333\n",
        "å“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆ\n"
    ]
}
```
### ğŸ‰ Output example

With inputs:
```
ï¼Ÿï¼Ÿï¼Ÿ
è¦è®©è€å¸ˆå°å¿ƒä¸€ç‚¹
å¤ªå¯çˆ±äº†
å‰é¢çš„æ³¥å¢äº†
æ²¡æœ‰è¶…ç¾ä¸½3dï¼Œç™½ç­‰äº†
ï¼Ÿæ²¡è§è¿‡è¿™ç§åŒ…æ³•å‘€
awsl
æ¥äº†æ¥äº†
å°é¢ä¸ºä»€ä¹ˆè¿™ä¹ˆéªš
åŒé—®
2333
ä¸‰æ¬¡å…ƒçš„æœ‹å‹ä¹Ÿä¸èƒ½æ”¾å¼ƒå•Š
awsl
awsl
awsl
```
Here are the outputs:
```
é˜¿ä¼Ÿå‡ºæ¥å—æ­»ï¼
wwwww
wwwwwwwwwwwwwwwwwwwwww
å¯çˆ±
awsl
awsl
awsl
è‰
awsl
awsl
çˆ±é…±å¥½å¯çˆ±
awsl
é˜¿ä¼Ÿå‡ºæ¥å—æ­»
awsl
awsl
awsl
114514
ä½ ä¸è¦è¿‡æ¥å•Š
é˜¿ä¼Ÿæ­»äº†
```

### âš¡ï¸ Quick start

First, create an instance and load the model. 

The program will be more time-consuming if you increase the parameter 'BATCH_SIZE', but you will get better results. So, there is a trade-off here. For instance, under current configuration, it took about 3 seconds to generate 20 fake danmakus on my computer. We could expect it to be much faster in a GPU.

```python
from model_process import model_process
'Initialize'
mp = model_process(BATCH_SIZE = 100)
'Create a generator, load in the trained model'
mp.prepare_for_generator()
```

Second, get the input data.
```python
'We assume we have the following inputs'
data = input_data().return_example_input_list()
input_data().show_input_data()
```
At this step, you should see the following outputs in the console. That's what the program expects as inputs:
```
read in data:
>> ä»Šæ™šæˆ‘ä¸ç¡äº†ï¼
>> åˆºæ¿€åˆºæ¿€
>> washoi
>> é©¬è‡ªç«‹å”±æ­Œâ€¦â€¦
>> çˆ·ä¸ç¡äº†
>> å¤å“¥æ’­ï¼Œæˆ‘å°±é™ªå¤å“¥ç†¬
>> å¤å“¥æ·±å¤œæ¡£
>> ï½‹ï½‹ï½“ï½‹
>> ç©å…‰æ˜ä¸Šä¸‹çš„å…ˆè¸¢äº†
>> ddä»¬æ¢ç‰Œå­
>> åŠå¤œå”±æ­Œï¼Ÿ
>> ã“ã‚“ã°ã‚“ã‚ã£ã—ã‚…ã„
>> washoi
>> washoi
>> (ï½€ãƒ»Ï‰ãƒ»Â´)ç‰™ç™½
```

Then, whenever the new data is available, feed it into the feed_in_data function. Here we use a for loop to simulate this process:
```python
'Use a loop to iterate the data'
for single_data in data:
    'Every time there is a new message available, feed in the data'
    returned_result = mp.feed_in_data(single_data)
```
Whenever there is enough data, the model will output the fake danmakus to the 'returned_result', which is a list. Otherwise, the list will be empty.
